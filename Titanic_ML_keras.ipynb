{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic ML_keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pli8uHLYffJv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "de3ac229-6d76-451d-98b6-c2f75670cafc"
      },
      "source": [
        "!pwd\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CcIxiu_fj3q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12cbae9b-613f-4e5f-8f59-a51d8e7ef077"
      },
      "source": [
        "#unzip and extract data files\n",
        "from zipfile import ZipFile\n",
        "file_name = \"titanic.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "    zip.extractall()\n",
        "    print(\"Done\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9GbQWrPkASi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "01dc8e4e-a523-40d4-a414-28599c3ec5ec"
      },
      "source": [
        "#load the train data\n",
        "import pandas as pd\n",
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_train.head(5)\n",
        "\n",
        "df_test = pd.read_csv(\"test.csv\")\n",
        "df_test.head(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>3</td>\n",
              "      <td>Kelly, Mr. James</td>\n",
              "      <td>male</td>\n",
              "      <td>34.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>330911</td>\n",
              "      <td>7.8292</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>3</td>\n",
              "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
              "      <td>female</td>\n",
              "      <td>47.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>363272</td>\n",
              "      <td>7.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>2</td>\n",
              "      <td>Myles, Mr. Thomas Francis</td>\n",
              "      <td>male</td>\n",
              "      <td>62.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>240276</td>\n",
              "      <td>9.6875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Q</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>3</td>\n",
              "      <td>Wirz, Mr. Albert</td>\n",
              "      <td>male</td>\n",
              "      <td>27.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>315154</td>\n",
              "      <td>8.6625</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>896</td>\n",
              "      <td>3</td>\n",
              "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
              "      <td>female</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3101298</td>\n",
              "      <td>12.2875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Pclass  ... Cabin Embarked\n",
              "0          892       3  ...   NaN        Q\n",
              "1          893       3  ...   NaN        S\n",
              "2          894       2  ...   NaN        Q\n",
              "3          895       3  ...   NaN        S\n",
              "4          896       3  ...   NaN        S\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uillugbGNB9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting sex to integers\n",
        "df_train['Sex']= df_train['Sex'].map({\"female\":1 , \"male\":0})\n",
        "df_test['Sex']= df_test['Sex'].map({\"female\":1 , \"male\":0})"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYhcUgSUNCO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "7017f08a-0470-4827-fd45-b4bb8b8752f5"
      },
      "source": [
        "#extract the titles from the names and label\n",
        "df_train['Title'] = df_train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "df_test['Title'] = df_test['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "\n",
        "# df_train['Title'].value_counts()\n",
        "# print(df_test['Title'].value_counts())\n",
        "\n",
        "titles = {\"Mr\": 1, \"Mrs\": 2, \"Miss\": 3, \"Master\": 4, \"Ms\":3, \"Lady\":3, \"Countess\":3, \"Mme\": 2, \n",
        "          \"Mlle\":3, \"Dr\":5, \"Rev\":5, \"Col\":5, \"Major\":5, \"Don\":5, \"Capt\":5, \"Sir\":5, \"Jonkheer\":5, \"Dona\":2 }   \n",
        "df_train['Title']= df_train['Title'].map(titles)\n",
        "df_test['Title']= df_test['Title'].map(titles)\n",
        "\n",
        "print(df_train['Title'].value_counts())\n",
        "print(df_test['Title'].value_counts())\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    517\n",
            "3    187\n",
            "2    126\n",
            "4     40\n",
            "5     21\n",
            "Name: Title, dtype: int64\n",
            "1    240\n",
            "3     79\n",
            "2     73\n",
            "4     21\n",
            "5      5\n",
            "Name: Title, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wbU2w7DNCYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Assign the median value of each title category to fill missing age values\n",
        "\n",
        "df_train.groupby('Title')['Age'].agg(['mean','median', 'min','max'])\n",
        "df_train['Age'].fillna(df_train.groupby('Title')['Age'].transform('median'), inplace=True)\n",
        "df_test['Age'].fillna(df_train.groupby('Title')['Age'].transform('median'), inplace=True)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJj1j1UmNCgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Check the class of missing Embarked passegers\n",
        "filt = (df_train['Embarked']=='S') | (df_train['Embarked']=='Q') | (df_train['Embarked']=='C')\n",
        "df_train.loc[~filt]\n",
        "\n",
        "#Assign S for those missing value\n",
        "df_train['Embarked'].fillna('S', inplace=True)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLI1yH9aNCoO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "f3b213ce-ff66-47f6-cd42-488a004ef4aa"
      },
      "source": [
        "#display the fare prices for Pclass\n",
        "print(df_train.groupby('Pclass')['Fare'].agg(['mean','median', 'min','max']))\n",
        "print('------------')\n",
        "print(df_test.groupby('Pclass')['Fare'].agg(['mean','median', 'min','max']))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             mean   median  min       max\n",
            "Pclass                                   \n",
            "1       84.154687  60.2875  0.0  512.3292\n",
            "2       20.662183  14.2500  0.0   73.5000\n",
            "3       13.675550   8.0500  0.0   69.5500\n",
            "------------\n",
            "             mean   median     min       max\n",
            "Pclass                                      \n",
            "1       94.280297  60.0000  0.0000  512.3292\n",
            "2       22.202104  15.7500  9.6875   73.5000\n",
            "3       12.459678   7.8958  3.1708   69.5500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxY3xHMMNCvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test['Fare'].fillna(df_train.groupby('Pclass')['Fare'].transform('mean'), inplace=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHFH1wW0NC14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#new column cabin_deck with the deck name exrtracted from cabin\n",
        "df_train['Cabin_deck'] = df_train['Cabin'].str[:1]\n",
        "df_test['Cabin_deck'] = df_test['Cabin'].str[:1]\n",
        "\n",
        "print(df_train['Cabin_deck'].value_counts())\n",
        "print(df_test['Cabin_deck'].value_counts())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kEsGMRNNC7p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Assign 'N' for all the missing cabin deck values\n",
        "df_train['Cabin_deck'].fillna(value='N', inplace=True)\n",
        "df_test['Cabin_deck'].fillna(value='N', inplace=True)\n",
        "\n",
        "#map the cabin values to intergers\n",
        "deck = {\"T\": 0, \"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\":5, \"F\":6, \"G\":7, \"N\":8}\n",
        "      \n",
        "df_train['Cabin_deck']= df_train['Cabin_deck'].map(deck)\n",
        "df_test['Cabin_deck']= df_test['Cabin_deck'].map(deck)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDM14DgDNDAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#mapping Embarked coumn to integers\n",
        "Embark = {'S':1, 'C':2, 'Q':3}\n",
        "\n",
        "df_train['Embarked']= df_train['Embarked'].map(Embark)\n",
        "df_test['Embarked']= df_test['Embarked'].map(Embark)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faVQBU5NNDE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#droping unwanted columns [Name, Ticket, Cabin, Ticket_pref]\n",
        "df_train.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
        "df_test.drop(['Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIiFGO1ANhtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting age to groups\n",
        "data = [df_train, df_test]\n",
        "for dataset in data:\n",
        "    dataset['Age'] = dataset['Age'].astype(int)\n",
        "    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n",
        "    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n",
        "    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n",
        "    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n",
        "    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n",
        "    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n",
        "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n",
        "    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4p98vL5Nh2M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#converting fare values to integers\n",
        "df_train['Fare'] = df_train['Fare'].astype(int)\n",
        "df_test['Fare'] = df_test['Fare'].astype(int)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9eSIRc-Nh9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = [df_train, df_test]\n",
        "for dataset in data:\n",
        "    dataset['family'] = dataset['SibSp']+ dataset['Parch']\n",
        "    dataset['Age_Class'] = dataset['Age']* dataset['Pclass']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmqPC3CiNiFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "30b4b360-bcaa-4698-935c-09d1932ef92b"
      },
      "source": [
        "#get the quantilevalues for Fare for grouping\n",
        "fare_arr = df_train['Fare'].values\n",
        "pd.qcut(fare_arr,6)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(-0.001, 7.0], (52.0, 512.0], (-0.001, 7.0], (52.0, 512.0], (7.0, 8.0], ..., (8.0, 14.0], (26.0, 52.0], (14.0, 26.0], (26.0, 52.0], (-0.001, 7.0]]\n",
              "Length: 891\n",
              "Categories (6, interval[float64]): [(-0.001, 7.0] < (7.0, 8.0] < (8.0, 14.0] < (14.0, 26.0] <\n",
              "                                    (26.0, 52.0] < (52.0, 512.0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZipVmb-NDJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#group the Fare based on 6 quantiles\n",
        "data = [df_train, df_test]\n",
        "for dataset in data:\n",
        "    dataset.loc[ dataset['Fare'] <= 7, 'Fare'] = 1\n",
        "    dataset.loc[(dataset['Fare'] > 7) & (dataset['Fare'] <= 8), 'Fare'] = 2\n",
        "    dataset.loc[(dataset['Fare'] > 8) & (dataset['Fare'] <= 14), 'Fare'] = 3\n",
        "    dataset.loc[(dataset['Fare'] > 14) & (dataset['Fare'] <= 26), 'Fare'] = 4\n",
        "    dataset.loc[(dataset['Fare'] > 26) & (dataset['Fare'] <= 52), 'Fare'] = 5\n",
        "    dataset.loc[dataset['Fare'] > 52, 'Fare'] = 6 \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qomR8pXPN2F4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9e31b3da-a899-4a54-bc3a-78408d3ff99e"
      },
      "source": [
        "df_test.head(3)\n",
        "df_train.head(3)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Title</th>\n",
              "      <th>Cabin_deck</th>\n",
              "      <th>family</th>\n",
              "      <th>Age_Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  Sex  ...  Title  Cabin_deck  family  Age_Class\n",
              "0            1         0       3    0  ...      1           8       1          6\n",
              "1            2         1       1    1  ...      2           3       1          5\n",
              "2            3         1       3    1  ...      3           8       0          9\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdWzxxxGN2K9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X and y selection\n",
        "X= df_train.drop(['Survived','PassengerId'], axis=1)\n",
        "y = df_train.Survived"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8alu1ggoN2QC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmUVQ3HDN2U-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rApSrAG2sa-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5c10e2e2-2c8a-45c0-f52e-6e653a83ccec"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGrQ35s-sl2z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f0efb5d-7b35-4f60-e96a-d1da6ecc3fe0"
      },
      "source": [
        "device= tf.test.gpu_device_name()\n",
        "print(device)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbVu1NuXVTiq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "6f356397-ff0c-42cf-db3b-36a7a5d08cbb"
      },
      "source": [
        "# df.dtypes\n",
        "X.info()\n",
        "X.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 11 columns):\n",
            " #   Column      Non-Null Count  Dtype\n",
            "---  ------      --------------  -----\n",
            " 0   Pclass      891 non-null    int64\n",
            " 1   Sex         891 non-null    int64\n",
            " 2   Age         891 non-null    int64\n",
            " 3   SibSp       891 non-null    int64\n",
            " 4   Parch       891 non-null    int64\n",
            " 5   Fare        891 non-null    int64\n",
            " 6   Embarked    891 non-null    int64\n",
            " 7   Title       891 non-null    int64\n",
            " 8   Cabin_deck  891 non-null    int64\n",
            " 9   family      891 non-null    int64\n",
            " 10  Age_Class   891 non-null    int64\n",
            "dtypes: int64(11)\n",
            "memory usage: 76.7 KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(891, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrSdM1JGQZrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcny8SdTQ5w9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from keras.optimizers import Adam, RMSprop\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NiLx5JlRAzZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "a8d5f33c-02b3-4bcf-dbbe-62d43e205b45"
      },
      "source": [
        "# create the sequential model\n",
        "tf.random.set_seed(0)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(20, activation='relu', input_shape=(11,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(30, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_4 (Dense)              (None, 20)                240       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 30)                630       \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 30)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 901\n",
            "Trainable params: 901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5zqjUX0RHvl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b1f5db8c-4f9b-4f6c-eea9-aefd2682c8a2"
      },
      "source": [
        "#Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(x= X, y= y, epochs =200)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "891/891 [==============================] - 0s 346us/step - loss: 0.3761 - accuracy: 0.8384\n",
            "Epoch 2/200\n",
            "891/891 [==============================] - 0s 162us/step - loss: 0.3792 - accuracy: 0.8429\n",
            "Epoch 3/200\n",
            "891/891 [==============================] - 0s 147us/step - loss: 0.3806 - accuracy: 0.8451\n",
            "Epoch 4/200\n",
            "891/891 [==============================] - 0s 146us/step - loss: 0.3798 - accuracy: 0.8361\n",
            "Epoch 5/200\n",
            "891/891 [==============================] - 0s 147us/step - loss: 0.3777 - accuracy: 0.8350\n",
            "Epoch 6/200\n",
            "891/891 [==============================] - 0s 147us/step - loss: 0.3872 - accuracy: 0.8418\n",
            "Epoch 7/200\n",
            "891/891 [==============================] - 0s 165us/step - loss: 0.3909 - accuracy: 0.8316\n",
            "Epoch 8/200\n",
            "891/891 [==============================] - 0s 160us/step - loss: 0.3725 - accuracy: 0.8485\n",
            "Epoch 9/200\n",
            "891/891 [==============================] - 0s 193us/step - loss: 0.3762 - accuracy: 0.8496\n",
            "Epoch 10/200\n",
            "891/891 [==============================] - 0s 160us/step - loss: 0.3813 - accuracy: 0.8440\n",
            "Epoch 11/200\n",
            "891/891 [==============================] - 0s 148us/step - loss: 0.3733 - accuracy: 0.8406\n",
            "Epoch 12/200\n",
            "891/891 [==============================] - 0s 153us/step - loss: 0.3809 - accuracy: 0.8418\n",
            "Epoch 13/200\n",
            "891/891 [==============================] - 0s 150us/step - loss: 0.3794 - accuracy: 0.8485\n",
            "Epoch 14/200\n",
            "891/891 [==============================] - 0s 150us/step - loss: 0.3835 - accuracy: 0.8429\n",
            "Epoch 15/200\n",
            "891/891 [==============================] - 0s 157us/step - loss: 0.3686 - accuracy: 0.8406\n",
            "Epoch 16/200\n",
            "891/891 [==============================] - 0s 197us/step - loss: 0.3761 - accuracy: 0.8440\n",
            "Epoch 17/200\n",
            "891/891 [==============================] - 0s 178us/step - loss: 0.3855 - accuracy: 0.8406\n",
            "Epoch 18/200\n",
            "891/891 [==============================] - 0s 136us/step - loss: 0.3718 - accuracy: 0.8496\n",
            "Epoch 19/200\n",
            "891/891 [==============================] - 0s 138us/step - loss: 0.3743 - accuracy: 0.8395\n",
            "Epoch 20/200\n",
            "891/891 [==============================] - 0s 143us/step - loss: 0.3756 - accuracy: 0.8373\n",
            "Epoch 21/200\n",
            "891/891 [==============================] - 0s 150us/step - loss: 0.3799 - accuracy: 0.8451\n",
            "Epoch 22/200\n",
            "891/891 [==============================] - 0s 151us/step - loss: 0.3734 - accuracy: 0.8406\n",
            "Epoch 23/200\n",
            "891/891 [==============================] - 0s 191us/step - loss: 0.3841 - accuracy: 0.8361\n",
            "Epoch 24/200\n",
            "891/891 [==============================] - 0s 155us/step - loss: 0.3669 - accuracy: 0.8350\n",
            "Epoch 25/200\n",
            "891/891 [==============================] - 0s 140us/step - loss: 0.3875 - accuracy: 0.8373\n",
            "Epoch 26/200\n",
            "891/891 [==============================] - 0s 158us/step - loss: 0.3769 - accuracy: 0.8418\n",
            "Epoch 27/200\n",
            "891/891 [==============================] - 0s 146us/step - loss: 0.3726 - accuracy: 0.8418\n",
            "Epoch 28/200\n",
            "891/891 [==============================] - 0s 141us/step - loss: 0.3815 - accuracy: 0.8406\n",
            "Epoch 29/200\n",
            "891/891 [==============================] - 0s 146us/step - loss: 0.3759 - accuracy: 0.8384\n",
            "Epoch 30/200\n",
            "891/891 [==============================] - 0s 153us/step - loss: 0.3794 - accuracy: 0.8384\n",
            "Epoch 31/200\n",
            "891/891 [==============================] - 0s 154us/step - loss: 0.3783 - accuracy: 0.8451\n",
            "Epoch 32/200\n",
            "891/891 [==============================] - 0s 164us/step - loss: 0.3751 - accuracy: 0.8485\n",
            "Epoch 33/200\n",
            "891/891 [==============================] - 0s 158us/step - loss: 0.3704 - accuracy: 0.8462\n",
            "Epoch 34/200\n",
            "891/891 [==============================] - 0s 178us/step - loss: 0.3795 - accuracy: 0.8395\n",
            "Epoch 35/200\n",
            "891/891 [==============================] - 0s 155us/step - loss: 0.3738 - accuracy: 0.8384\n",
            "Epoch 36/200\n",
            "891/891 [==============================] - 0s 146us/step - loss: 0.3801 - accuracy: 0.8429\n",
            "Epoch 37/200\n",
            "891/891 [==============================] - 0s 157us/step - loss: 0.3886 - accuracy: 0.8260\n",
            "Epoch 38/200\n",
            "891/891 [==============================] - 0s 164us/step - loss: 0.3670 - accuracy: 0.8429\n",
            "Epoch 39/200\n",
            "891/891 [==============================] - 0s 147us/step - loss: 0.3731 - accuracy: 0.8462\n",
            "Epoch 40/200\n",
            "891/891 [==============================] - 0s 149us/step - loss: 0.3547 - accuracy: 0.8519\n",
            "Epoch 41/200\n",
            "891/891 [==============================] - 0s 147us/step - loss: 0.3725 - accuracy: 0.8541\n",
            "Epoch 42/200\n",
            "891/891 [==============================] - 0s 144us/step - loss: 0.3795 - accuracy: 0.8429\n",
            "Epoch 43/200\n",
            "891/891 [==============================] - 0s 161us/step - loss: 0.3801 - accuracy: 0.8361\n",
            "Epoch 44/200\n",
            "891/891 [==============================] - 0s 159us/step - loss: 0.3735 - accuracy: 0.8384\n",
            "Epoch 45/200\n",
            "891/891 [==============================] - 0s 167us/step - loss: 0.3715 - accuracy: 0.8440\n",
            "Epoch 46/200\n",
            "891/891 [==============================] - 0s 153us/step - loss: 0.3642 - accuracy: 0.8429\n",
            "Epoch 47/200\n",
            "891/891 [==============================] - 0s 150us/step - loss: 0.3737 - accuracy: 0.8440\n",
            "Epoch 48/200\n",
            "891/891 [==============================] - 0s 153us/step - loss: 0.3758 - accuracy: 0.8462\n",
            "Epoch 49/200\n",
            "891/891 [==============================] - 0s 154us/step - loss: 0.3661 - accuracy: 0.8440\n",
            "Epoch 50/200\n",
            "891/891 [==============================] - 0s 158us/step - loss: 0.3749 - accuracy: 0.8316\n",
            "Epoch 51/200\n",
            "891/891 [==============================] - 0s 146us/step - loss: 0.3781 - accuracy: 0.8373\n",
            "Epoch 52/200\n",
            "891/891 [==============================] - 0s 203us/step - loss: 0.3647 - accuracy: 0.8530\n",
            "Epoch 53/200\n",
            "891/891 [==============================] - 0s 151us/step - loss: 0.3621 - accuracy: 0.8507\n",
            "Epoch 54/200\n",
            "891/891 [==============================] - 0s 150us/step - loss: 0.3743 - accuracy: 0.8429\n",
            "Epoch 55/200\n",
            "891/891 [==============================] - 0s 152us/step - loss: 0.3703 - accuracy: 0.8316\n",
            "Epoch 56/200\n",
            "891/891 [==============================] - 0s 156us/step - loss: 0.3664 - accuracy: 0.8541\n",
            "Epoch 57/200\n",
            "891/891 [==============================] - 0s 152us/step - loss: 0.3736 - accuracy: 0.8451\n",
            "Epoch 58/200\n",
            "891/891 [==============================] - 0s 163us/step - loss: 0.3622 - accuracy: 0.8541\n",
            "Epoch 59/200\n",
            "891/891 [==============================] - 0s 171us/step - loss: 0.3742 - accuracy: 0.8541\n",
            "Epoch 60/200\n",
            "891/891 [==============================] - 0s 174us/step - loss: 0.3670 - accuracy: 0.8384\n",
            "Epoch 61/200\n",
            "891/891 [==============================] - 0s 168us/step - loss: 0.3705 - accuracy: 0.8395\n",
            "Epoch 62/200\n",
            "891/891 [==============================] - 0s 164us/step - loss: 0.3713 - accuracy: 0.8384\n",
            "Epoch 63/200\n",
            "891/891 [==============================] - 0s 157us/step - loss: 0.3697 - accuracy: 0.8406\n",
            "Epoch 64/200\n",
            "891/891 [==============================] - 0s 151us/step - loss: 0.3760 - accuracy: 0.8328\n",
            "Epoch 65/200\n",
            "891/891 [==============================] - 0s 172us/step - loss: 0.3780 - accuracy: 0.8384\n",
            "Epoch 66/200\n",
            "891/891 [==============================] - 0s 169us/step - loss: 0.3665 - accuracy: 0.8620\n",
            "Epoch 67/200\n",
            "891/891 [==============================] - 0s 155us/step - loss: 0.3649 - accuracy: 0.8395\n",
            "Epoch 68/200\n",
            "891/891 [==============================] - 0s 140us/step - loss: 0.3739 - accuracy: 0.8474\n",
            "Epoch 69/200\n",
            "891/891 [==============================] - 0s 156us/step - loss: 0.3787 - accuracy: 0.8418\n",
            "Epoch 70/200\n",
            "891/891 [==============================] - 0s 141us/step - loss: 0.3658 - accuracy: 0.8462\n",
            "Epoch 71/200\n",
            "891/891 [==============================] - 0s 145us/step - loss: 0.3653 - accuracy: 0.8485\n",
            "Epoch 72/200\n",
            "891/891 [==============================] - 0s 154us/step - loss: 0.3622 - accuracy: 0.8384\n",
            "Epoch 73/200\n",
            "891/891 [==============================] - 0s 173us/step - loss: 0.3663 - accuracy: 0.8418\n",
            "Epoch 74/200\n",
            "891/891 [==============================] - 0s 149us/step - loss: 0.3700 - accuracy: 0.8429\n",
            "Epoch 75/200\n",
            "891/891 [==============================] - 0s 145us/step - loss: 0.3724 - accuracy: 0.8451\n",
            "Epoch 76/200\n",
            "891/891 [==============================] - 0s 143us/step - loss: 0.3786 - accuracy: 0.8406\n",
            "Epoch 77/200\n",
            "891/891 [==============================] - 0s 159us/step - loss: 0.3634 - accuracy: 0.8373\n",
            "Epoch 78/200\n",
            "891/891 [==============================] - 0s 150us/step - loss: 0.3653 - accuracy: 0.8440\n",
            "Epoch 79/200\n",
            "891/891 [==============================] - 0s 143us/step - loss: 0.3770 - accuracy: 0.8440\n",
            "Epoch 80/200\n",
            "891/891 [==============================] - 0s 162us/step - loss: 0.3628 - accuracy: 0.8406\n",
            "Epoch 81/200\n",
            "891/891 [==============================] - 0s 169us/step - loss: 0.3610 - accuracy: 0.8474\n",
            "Epoch 82/200\n",
            "891/891 [==============================] - 0s 158us/step - loss: 0.3761 - accuracy: 0.8451\n",
            "Epoch 83/200\n",
            "891/891 [==============================] - 0s 154us/step - loss: 0.3569 - accuracy: 0.8451\n",
            "Epoch 84/200\n",
            "891/891 [==============================] - 0s 160us/step - loss: 0.3645 - accuracy: 0.8462\n",
            "Epoch 85/200\n",
            "891/891 [==============================] - 0s 160us/step - loss: 0.3609 - accuracy: 0.8519\n",
            "Epoch 86/200\n",
            "891/891 [==============================] - 0s 164us/step - loss: 0.3654 - accuracy: 0.8462\n",
            "Epoch 87/200\n",
            "891/891 [==============================] - 0s 164us/step - loss: 0.3694 - accuracy: 0.8384\n",
            "Epoch 88/200\n",
            "891/891 [==============================] - 0s 160us/step - loss: 0.3696 - accuracy: 0.8474\n",
            "Epoch 89/200\n",
            "891/891 [==============================] - 0s 144us/step - loss: 0.3765 - accuracy: 0.8384\n",
            "Epoch 90/200\n",
            "891/891 [==============================] - 0s 145us/step - loss: 0.3633 - accuracy: 0.8563\n",
            "Epoch 91/200\n",
            "891/891 [==============================] - 0s 144us/step - loss: 0.3647 - accuracy: 0.8541\n",
            "Epoch 92/200\n",
            "891/891 [==============================] - 0s 155us/step - loss: 0.3675 - accuracy: 0.8530\n",
            "Epoch 93/200\n",
            "891/891 [==============================] - 0s 158us/step - loss: 0.3565 - accuracy: 0.8496\n",
            "Epoch 94/200\n",
            "891/891 [==============================] - 0s 158us/step - loss: 0.3634 - accuracy: 0.8541\n",
            "Epoch 95/200\n",
            "891/891 [==============================] - 0s 154us/step - loss: 0.3680 - accuracy: 0.8541\n",
            "Epoch 96/200\n",
            "891/891 [==============================] - 0s 158us/step - loss: 0.3689 - accuracy: 0.8462\n",
            "Epoch 97/200\n",
            "891/891 [==============================] - 0s 144us/step - loss: 0.3706 - accuracy: 0.8530\n",
            "Epoch 98/200\n",
            "891/891 [==============================] - 0s 147us/step - loss: 0.3708 - accuracy: 0.8474\n",
            "Epoch 99/200\n",
            "891/891 [==============================] - 0s 141us/step - loss: 0.3700 - accuracy: 0.8418\n",
            "Epoch 100/200\n",
            "891/891 [==============================] - 0s 144us/step - loss: 0.3599 - accuracy: 0.8474\n",
            "Epoch 101/200\n",
            "891/891 [==============================] - 0s 169us/step - loss: 0.3578 - accuracy: 0.8563\n",
            "Epoch 102/200\n",
            "891/891 [==============================] - 0s 192us/step - loss: 0.3705 - accuracy: 0.8395\n",
            "Epoch 103/200\n",
            "891/891 [==============================] - 0s 140us/step - loss: 0.3686 - accuracy: 0.8462\n",
            "Epoch 104/200\n",
            "891/891 [==============================] - 0s 185us/step - loss: 0.3673 - accuracy: 0.8418\n",
            "Epoch 105/200\n",
            "891/891 [==============================] - 0s 182us/step - loss: 0.3689 - accuracy: 0.8462\n",
            "Epoch 106/200\n",
            "891/891 [==============================] - 0s 172us/step - loss: 0.3753 - accuracy: 0.8440\n",
            "Epoch 107/200\n",
            "891/891 [==============================] - 0s 163us/step - loss: 0.3678 - accuracy: 0.8530\n",
            "Epoch 108/200\n",
            "891/891 [==============================] - 0s 156us/step - loss: 0.3706 - accuracy: 0.8462\n",
            "Epoch 109/200\n",
            "891/891 [==============================] - 0s 164us/step - loss: 0.3646 - accuracy: 0.8496\n",
            "Epoch 110/200\n",
            "891/891 [==============================] - 0s 158us/step - loss: 0.3614 - accuracy: 0.8597\n",
            "Epoch 111/200\n",
            "891/891 [==============================] - 0s 162us/step - loss: 0.3636 - accuracy: 0.8496\n",
            "Epoch 112/200\n",
            "891/891 [==============================] - 0s 152us/step - loss: 0.3684 - accuracy: 0.8507\n",
            "Epoch 113/200\n",
            "891/891 [==============================] - 0s 146us/step - loss: 0.3755 - accuracy: 0.8462\n",
            "Epoch 114/200\n",
            "891/891 [==============================] - 0s 151us/step - loss: 0.3647 - accuracy: 0.8575\n",
            "Epoch 115/200\n",
            "891/891 [==============================] - 0s 168us/step - loss: 0.3649 - accuracy: 0.8474\n",
            "Epoch 116/200\n",
            "891/891 [==============================] - 0s 158us/step - loss: 0.3767 - accuracy: 0.8474\n",
            "Epoch 117/200\n",
            "891/891 [==============================] - 0s 159us/step - loss: 0.3567 - accuracy: 0.8384\n",
            "Epoch 118/200\n",
            "891/891 [==============================] - 0s 175us/step - loss: 0.3618 - accuracy: 0.8519\n",
            "Epoch 119/200\n",
            "891/891 [==============================] - 0s 178us/step - loss: 0.3638 - accuracy: 0.8552\n",
            "Epoch 120/200\n",
            "891/891 [==============================] - 0s 147us/step - loss: 0.3529 - accuracy: 0.8462\n",
            "Epoch 121/200\n",
            "891/891 [==============================] - 0s 155us/step - loss: 0.3646 - accuracy: 0.8597\n",
            "Epoch 122/200\n",
            "891/891 [==============================] - 0s 150us/step - loss: 0.3689 - accuracy: 0.8418\n",
            "Epoch 123/200\n",
            "891/891 [==============================] - 0s 159us/step - loss: 0.3628 - accuracy: 0.8519\n",
            "Epoch 124/200\n",
            "891/891 [==============================] - 0s 143us/step - loss: 0.3647 - accuracy: 0.8586\n",
            "Epoch 125/200\n",
            "891/891 [==============================] - 0s 148us/step - loss: 0.3775 - accuracy: 0.8418\n",
            "Epoch 126/200\n",
            "891/891 [==============================] - 0s 145us/step - loss: 0.3646 - accuracy: 0.8451\n",
            "Epoch 127/200\n",
            "891/891 [==============================] - 0s 149us/step - loss: 0.3620 - accuracy: 0.8496\n",
            "Epoch 128/200\n",
            "891/891 [==============================] - 0s 150us/step - loss: 0.3667 - accuracy: 0.8462\n",
            "Epoch 129/200\n",
            "891/891 [==============================] - 0s 161us/step - loss: 0.3618 - accuracy: 0.8485\n",
            "Epoch 130/200\n",
            "891/891 [==============================] - 0s 163us/step - loss: 0.3668 - accuracy: 0.8507\n",
            "Epoch 131/200\n",
            "891/891 [==============================] - 0s 146us/step - loss: 0.3611 - accuracy: 0.8519\n",
            "Epoch 132/200\n",
            "891/891 [==============================] - 0s 151us/step - loss: 0.3641 - accuracy: 0.8474\n",
            "Epoch 133/200\n",
            "891/891 [==============================] - 0s 150us/step - loss: 0.3613 - accuracy: 0.8418\n",
            "Epoch 134/200\n",
            "891/891 [==============================] - 0s 146us/step - loss: 0.3595 - accuracy: 0.8620\n",
            "Epoch 135/200\n",
            "891/891 [==============================] - 0s 154us/step - loss: 0.3555 - accuracy: 0.8586\n",
            "Epoch 136/200\n",
            "891/891 [==============================] - 0s 170us/step - loss: 0.3661 - accuracy: 0.8418\n",
            "Epoch 137/200\n",
            "891/891 [==============================] - 0s 156us/step - loss: 0.3598 - accuracy: 0.8530\n",
            "Epoch 138/200\n",
            "891/891 [==============================] - 0s 158us/step - loss: 0.3575 - accuracy: 0.8575\n",
            "Epoch 139/200\n",
            "891/891 [==============================] - 0s 149us/step - loss: 0.3705 - accuracy: 0.8530\n",
            "Epoch 140/200\n",
            "891/891 [==============================] - 0s 161us/step - loss: 0.3689 - accuracy: 0.8406\n",
            "Epoch 141/200\n",
            "891/891 [==============================] - 0s 179us/step - loss: 0.3618 - accuracy: 0.8384\n",
            "Epoch 142/200\n",
            "891/891 [==============================] - 0s 157us/step - loss: 0.3651 - accuracy: 0.8451\n",
            "Epoch 143/200\n",
            "891/891 [==============================] - 0s 163us/step - loss: 0.3610 - accuracy: 0.8474\n",
            "Epoch 144/200\n",
            "891/891 [==============================] - 0s 152us/step - loss: 0.3562 - accuracy: 0.8451\n",
            "Epoch 145/200\n",
            "891/891 [==============================] - 0s 175us/step - loss: 0.3602 - accuracy: 0.8406\n",
            "Epoch 146/200\n",
            "891/891 [==============================] - 0s 141us/step - loss: 0.3518 - accuracy: 0.8552\n",
            "Epoch 147/200\n",
            "891/891 [==============================] - 0s 140us/step - loss: 0.3702 - accuracy: 0.8429\n",
            "Epoch 148/200\n",
            "891/891 [==============================] - 0s 145us/step - loss: 0.3675 - accuracy: 0.8429\n",
            "Epoch 149/200\n",
            "891/891 [==============================] - 0s 146us/step - loss: 0.3662 - accuracy: 0.8462\n",
            "Epoch 150/200\n",
            "891/891 [==============================] - 0s 166us/step - loss: 0.3666 - accuracy: 0.8451\n",
            "Epoch 151/200\n",
            "891/891 [==============================] - 0s 148us/step - loss: 0.3627 - accuracy: 0.8384\n",
            "Epoch 152/200\n",
            "891/891 [==============================] - 0s 170us/step - loss: 0.3617 - accuracy: 0.8507\n",
            "Epoch 153/200\n",
            "891/891 [==============================] - 0s 146us/step - loss: 0.3492 - accuracy: 0.8597\n",
            "Epoch 154/200\n",
            "891/891 [==============================] - 0s 157us/step - loss: 0.3527 - accuracy: 0.8496\n",
            "Epoch 155/200\n",
            "891/891 [==============================] - 0s 150us/step - loss: 0.3633 - accuracy: 0.8440\n",
            "Epoch 156/200\n",
            "891/891 [==============================] - 0s 155us/step - loss: 0.3620 - accuracy: 0.8552\n",
            "Epoch 157/200\n",
            "891/891 [==============================] - 0s 140us/step - loss: 0.3649 - accuracy: 0.8519\n",
            "Epoch 158/200\n",
            "891/891 [==============================] - 0s 151us/step - loss: 0.3763 - accuracy: 0.8361\n",
            "Epoch 159/200\n",
            "891/891 [==============================] - 0s 152us/step - loss: 0.3699 - accuracy: 0.8485\n",
            "Epoch 160/200\n",
            "891/891 [==============================] - 0s 148us/step - loss: 0.3670 - accuracy: 0.8519\n",
            "Epoch 161/200\n",
            "891/891 [==============================] - 0s 142us/step - loss: 0.3549 - accuracy: 0.8462\n",
            "Epoch 162/200\n",
            "891/891 [==============================] - 0s 156us/step - loss: 0.3434 - accuracy: 0.8597\n",
            "Epoch 163/200\n",
            "891/891 [==============================] - 0s 150us/step - loss: 0.3626 - accuracy: 0.8496\n",
            "Epoch 164/200\n",
            "891/891 [==============================] - 0s 149us/step - loss: 0.3672 - accuracy: 0.8451\n",
            "Epoch 165/200\n",
            "891/891 [==============================] - 0s 155us/step - loss: 0.3634 - accuracy: 0.8530\n",
            "Epoch 166/200\n",
            "891/891 [==============================] - 0s 146us/step - loss: 0.3488 - accuracy: 0.8732\n",
            "Epoch 167/200\n",
            "891/891 [==============================] - 0s 154us/step - loss: 0.3604 - accuracy: 0.8485\n",
            "Epoch 168/200\n",
            "891/891 [==============================] - 0s 146us/step - loss: 0.3537 - accuracy: 0.8541\n",
            "Epoch 169/200\n",
            "891/891 [==============================] - 0s 141us/step - loss: 0.3560 - accuracy: 0.8519\n",
            "Epoch 170/200\n",
            "891/891 [==============================] - 0s 143us/step - loss: 0.3558 - accuracy: 0.8642\n",
            "Epoch 171/200\n",
            "891/891 [==============================] - 0s 144us/step - loss: 0.3535 - accuracy: 0.8530\n",
            "Epoch 172/200\n",
            "891/891 [==============================] - 0s 153us/step - loss: 0.3594 - accuracy: 0.8552\n",
            "Epoch 173/200\n",
            "891/891 [==============================] - 0s 138us/step - loss: 0.3665 - accuracy: 0.8496\n",
            "Epoch 174/200\n",
            "891/891 [==============================] - 0s 149us/step - loss: 0.3540 - accuracy: 0.8496\n",
            "Epoch 175/200\n",
            "891/891 [==============================] - 0s 150us/step - loss: 0.3483 - accuracy: 0.8530\n",
            "Epoch 176/200\n",
            "891/891 [==============================] - 0s 169us/step - loss: 0.3535 - accuracy: 0.8575\n",
            "Epoch 177/200\n",
            "891/891 [==============================] - 0s 155us/step - loss: 0.3606 - accuracy: 0.8541\n",
            "Epoch 178/200\n",
            "891/891 [==============================] - 0s 140us/step - loss: 0.3656 - accuracy: 0.8530\n",
            "Epoch 179/200\n",
            "891/891 [==============================] - 0s 140us/step - loss: 0.3521 - accuracy: 0.8474\n",
            "Epoch 180/200\n",
            "891/891 [==============================] - 0s 154us/step - loss: 0.3643 - accuracy: 0.8418\n",
            "Epoch 181/200\n",
            "891/891 [==============================] - 0s 146us/step - loss: 0.3609 - accuracy: 0.8608\n",
            "Epoch 182/200\n",
            "891/891 [==============================] - 0s 154us/step - loss: 0.3672 - accuracy: 0.8373\n",
            "Epoch 183/200\n",
            "891/891 [==============================] - 0s 142us/step - loss: 0.3498 - accuracy: 0.8530\n",
            "Epoch 184/200\n",
            "891/891 [==============================] - 0s 141us/step - loss: 0.3615 - accuracy: 0.8474\n",
            "Epoch 185/200\n",
            "891/891 [==============================] - 0s 144us/step - loss: 0.3581 - accuracy: 0.8496\n",
            "Epoch 186/200\n",
            "891/891 [==============================] - 0s 140us/step - loss: 0.3670 - accuracy: 0.8474\n",
            "Epoch 187/200\n",
            "891/891 [==============================] - 0s 151us/step - loss: 0.3757 - accuracy: 0.8406\n",
            "Epoch 188/200\n",
            "891/891 [==============================] - 0s 142us/step - loss: 0.3462 - accuracy: 0.8586\n",
            "Epoch 189/200\n",
            "891/891 [==============================] - 0s 148us/step - loss: 0.3690 - accuracy: 0.8462\n",
            "Epoch 190/200\n",
            "891/891 [==============================] - 0s 152us/step - loss: 0.3517 - accuracy: 0.8530\n",
            "Epoch 191/200\n",
            "891/891 [==============================] - 0s 172us/step - loss: 0.3482 - accuracy: 0.8575\n",
            "Epoch 192/200\n",
            "891/891 [==============================] - 0s 166us/step - loss: 0.3688 - accuracy: 0.8440\n",
            "Epoch 193/200\n",
            "891/891 [==============================] - 0s 137us/step - loss: 0.3671 - accuracy: 0.8496\n",
            "Epoch 194/200\n",
            "891/891 [==============================] - 0s 154us/step - loss: 0.3640 - accuracy: 0.8519\n",
            "Epoch 195/200\n",
            "891/891 [==============================] - 0s 149us/step - loss: 0.3677 - accuracy: 0.8530\n",
            "Epoch 196/200\n",
            "891/891 [==============================] - 0s 138us/step - loss: 0.3663 - accuracy: 0.8496\n",
            "Epoch 197/200\n",
            "891/891 [==============================] - 0s 144us/step - loss: 0.3742 - accuracy: 0.8451\n",
            "Epoch 198/200\n",
            "891/891 [==============================] - 0s 140us/step - loss: 0.3545 - accuracy: 0.8507\n",
            "Epoch 199/200\n",
            "891/891 [==============================] - 0s 139us/step - loss: 0.3661 - accuracy: 0.8451\n",
            "Epoch 200/200\n",
            "891/891 [==============================] - 0s 145us/step - loss: 0.3614 - accuracy: 0.8474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f0add00f7f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y75pX4K2Sy3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#prepare the test data for prediction\n",
        "df_test.head(3)\n",
        "passenger_Id = df_test['PassengerId']\n",
        "X_test_final = df_test.drop('PassengerId', axis =1)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ccDml8hR90o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict_classes(X_test_final)\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgmCn0kpTUWc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64c65b3d-0719-4648-b28f-9f9031699e1b"
      },
      "source": [
        "# rounded = [round(x[0]) for x in y_pred]\n",
        "# print(rounded)\n",
        "y_pred_final = y_pred.reshape(1,-1)\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03JWaz_WTICw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get the answer to a df with passengerID and survived columns\n",
        "y_pred_series = pd.Series(y_pred_final[0], name='Survived')\n",
        "answer_df= pd.concat([passenger_Id, y_pred_series], axis =1)\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DfTG_PxZJv8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "c988fe77-d53b-4185-fd4a-858bba6c6489"
      },
      "source": [
        "from google.colab import files\n",
        "answer_df.to_csv('titanic_keras.csv', index=False) \n",
        "files.download('titanic_keras.csv')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_628fc51f-1846-4d87-9ad1-403045d81681\", \"titanic_keras.csv\", 2839)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}